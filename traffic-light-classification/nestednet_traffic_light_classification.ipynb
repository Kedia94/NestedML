{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys, os, time\n",
    "import itertools\n",
    "import math, random\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from NestedNet START\n",
    "\n",
    "#temp variables\n",
    "BN_DECAY = 0.999\n",
    "BN_EPSILON = 0.00001\n",
    "\n",
    "# channel scheduling factors (now, 3 levels for conv scheduling)\n",
    "l2r = 1.0/2.0    # actual density: (l2r^2) *100\n",
    "l1r = 1.0/4.0    # actual density: (l1r^2) *100\n",
    "\n",
    "def create_variables(name, shape):\n",
    "\n",
    "    n1 = np.sqrt(6. / (shape[0] * shape[1] * l1r * (shape[-2] + shape[-1])))\n",
    "    n2 = np.sqrt(6. / (shape[0] * shape[1] * l2r * (shape[-2] + shape[-1])))\n",
    "    n3 = np.sqrt(6. / (shape[0] * shape[1] * (shape[-2] + shape[-1])))\n",
    "\n",
    "    shape1 = [shape[0], shape[1], int(l1r * shape[2]), int(l1r * shape[3])]\n",
    "    shape2_1 = [shape[0], shape[1], int((l2r - l1r) * shape[2]), int(l1r * shape[3])]\n",
    "    shape2_2 = [shape[0], shape[1], int(l2r * shape[2]), int((l2r - l1r) * shape[3])]\n",
    "    shape3_1 = [shape[0], shape[1], int((1. - l2r) * shape[2]), int(l2r * shape[3])]\n",
    "    shape3_2 = [shape[0], shape[1], shape[2], int((1. - l2r) * shape[3])]\n",
    "\n",
    "    lv1_variables = tf.get_variable(name + '_l1', initializer=tf.random_uniform(shape1, -n3, n3, tf.float32, seed=None))\n",
    "    lv2_1_variables = tf.get_variable(name + '_l2_1', initializer=tf.random_uniform(shape2_1, -n3, n3, tf.float32, seed=None))\n",
    "    lv2_2_variables = tf.get_variable(name + '_l2_2', initializer=tf.random_uniform(shape2_2, -n3, n3, tf.float32, seed=None))\n",
    "    lv3_1_variables = tf.get_variable(name + '_l3_1', initializer=tf.random_uniform(shape3_1, -n3, n3, tf.float32, seed=None))\n",
    "    lv3_2_variables = tf.get_variable(name + '_l3_2', initializer=tf.random_uniform(shape3_2, -n3, n3, tf.float32, seed=None))\n",
    "\n",
    "    return lv1_variables, lv2_1_variables, lv2_2_variables, lv3_1_variables, lv3_2_variables\n",
    "\n",
    "def output_layer(input1, input2, input3, num_labels):\n",
    "\n",
    "    input_dim1 = input1.get_shape().as_list()[-1]\n",
    "    input_dim2 = input2.get_shape().as_list()[-1]\n",
    "    input_dim3 = input3.get_shape().as_list()[-1]\n",
    "\n",
    "    fc_w1 = tf.get_variable('fc_weights_l1', shape=[input_dim1, num_labels], initializer=tf.initializers.variance_scaling(scale=1.0))\n",
    "    fc_w2 = tf.get_variable('fc_weights_l2', shape=[input_dim2, num_labels], initializer=tf.initializers.variance_scaling(scale=1.0))\n",
    "    fc_w3 = tf.get_variable('fc_weights_l3', shape=[input_dim3, num_labels], initializer=tf.initializers.variance_scaling(scale=1.0))\n",
    "\n",
    "    fc_b1 = tf.get_variable(name='fc_bias_l1', shape=[num_labels], initializer=tf.zeros_initializer())\n",
    "    fc_b2 = tf.get_variable(name='fc_bias_l2', shape=[num_labels], initializer=tf.zeros_initializer())\n",
    "    fc_b3 = tf.get_variable(name='fc_bias_l3', shape=[num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    fc_h1 = tf.matmul(input1, fc_w1) + fc_b1\n",
    "    fc_h2 = tf.matmul(input2, fc_w2) + fc_b2\n",
    "    fc_h3 = tf.matmul(input3, fc_w3) + fc_b3\n",
    "    return fc_h1, fc_h2, fc_h3\n",
    "\n",
    "def batch_normalization_layer(name, input_layer, dimension, is_training=True):\n",
    "\n",
    "    beta = tf.get_variable(name + 'beta', dimension, tf.float32, initializer=tf.constant_initializer(0.0, tf.float32))\n",
    "    gamma = tf.get_variable(name + 'gamma', dimension, tf.float32, initializer=tf.constant_initializer(1.0, tf.float32))\n",
    "    mu = tf.get_variable(name + 'mu', dimension, tf.float32, initializer=tf.constant_initializer(0.0, tf.float32), trainable=False)\n",
    "    sigma = tf.get_variable(name + 'sigma', dimension, tf.float32, initializer=tf.constant_initializer(1.0, tf.float32), trainable=False)\n",
    "\n",
    "    if is_training is True:\n",
    "        mean, variance = tf.nn.moments(input_layer, axes=[0, 1, 2])\n",
    "        train_mean = tf.assign(mu, mu * BN_DECAY + mean * (1 - BN_DECAY))\n",
    "        train_var = tf.assign(sigma, sigma * BN_DECAY + variance * (1 - BN_DECAY))\n",
    "\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(input_layer, mean, variance, beta, gamma, BN_EPSILON)\n",
    "    else:\n",
    "        bn_layer = tf.nn.batch_normalization(input_layer, mu, sigma, beta, gamma, BN_EPSILON)\n",
    "\n",
    "    return bn_layer\n",
    "\n",
    "\n",
    "def conv_layer(input_layer, filter_shape, stride, is_training):\n",
    "\n",
    "    in_channel = input_layer.get_shape().as_list()[-1]\n",
    "\n",
    "    bn_layer = batch_normalization_layer('l1_l2_l3', input_layer, in_channel, is_training)\n",
    "    bn_layer = tf.nn.relu(bn_layer)\n",
    "\n",
    "    n1 = np.sqrt(6. / (filter_shape[0] * filter_shape[1] * (filter_shape[-2] + l1r * filter_shape[-1])))\n",
    "    n2 = np.sqrt(6. / (filter_shape[0] * filter_shape[1] * (filter_shape[-2] + l2r * filter_shape[-1])))\n",
    "    n3 = np.sqrt(6. / (filter_shape[0] * filter_shape[1] * (filter_shape[-2] + filter_shape[-1])))\n",
    "    filter1 = tf.get_variable('conv_l1',\n",
    "                              initializer=tf.random_uniform([filter_shape[0], filter_shape[1], filter_shape[2], int(l1r*filter_shape[3])],\n",
    "                                                            -n3, n3,   tf.float32, seed=None))\n",
    "    filter2 = tf.get_variable('conv_l2',\n",
    "                              initializer=tf.random_uniform([filter_shape[0], filter_shape[1], filter_shape[2], int((l2r-l1r)*filter_shape[3])],\n",
    "                                                            -n3, n3,   tf.float32, seed=None))\n",
    "    filter3 = tf.get_variable('conv_l3',\n",
    "                              initializer=tf.random_uniform([filter_shape[0], filter_shape[1], filter_shape[2], int((1.-l2r)*filter_shape[3])],\n",
    "                                                            -n3, n3,   tf.float32, seed=None))\n",
    "\n",
    "    conv1 = tf.nn.conv2d(bn_layer, filter1, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    conv2 = tf.concat((conv1, tf.nn.conv2d(bn_layer, filter2, strides=[1, stride, stride, 1], padding='SAME')), 3)\n",
    "    conv3 = tf.concat((conv2, tf.nn.conv2d(bn_layer, filter3, strides=[1, stride, stride, 1], padding='SAME')), 3)\n",
    "\n",
    "    return conv1, conv2, conv3\n",
    "\n",
    "\n",
    "def bn_relu_conv_layer(input1, input2, input3, filter_shape, stride, is_training):\n",
    "\n",
    "    in_channel1 = input1.get_shape().as_list()[-1]\n",
    "    in_channel2 = input2.get_shape().as_list()[-1]\n",
    "    in_channel3 = input3.get_shape().as_list()[-1]\n",
    "\n",
    "    bn_layer1 = batch_normalization_layer('l1', input1, in_channel1, is_training)\n",
    "    bn_layer1 = tf.nn.relu(bn_layer1)\n",
    "    bn_layer2 = batch_normalization_layer('l2', input2, in_channel2, is_training)\n",
    "    bn_layer2 = tf.nn.relu(bn_layer2)\n",
    "    bn_layer3 = batch_normalization_layer('l3', input3, in_channel3, is_training)\n",
    "    bn_layer3 = tf.nn.relu(bn_layer3)\n",
    "\n",
    "    filter1, filter2_1, filter2_2, filter3_1, filter3_2 = create_variables(name='conv', shape=filter_shape)\n",
    "\n",
    "    conv1 = tf.nn.conv2d(bn_layer1, filter1, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    conv2 = tf.concat((tf.add(tf.nn.conv2d(bn_layer2[:, :, :, :int(l1r * filter_shape[2])], filter1, strides=[1, stride, stride, 1], padding='SAME'),\n",
    "                              tf.nn.conv2d(bn_layer2[:, :, :, int(l1r * filter_shape[2]):int(l2r * filter_shape[2])], filter2_1, strides=[1, stride, stride, 1],\n",
    "                                           padding='SAME')),\n",
    "                       tf.nn.conv2d(bn_layer2, filter2_2, strides=[1, stride, stride, 1], padding='SAME')), 3)\n",
    "    conv3 = tf.concat((tf.add(tf.nn.conv2d(bn_layer3[:, :, :, :int(l1r * filter_shape[2])], filter1, strides=[1, stride, stride, 1], padding='SAME'),\n",
    "                              tf.nn.conv2d(bn_layer3[:, :, :, int(l1r * filter_shape[2]):int(l2r * filter_shape[2])], filter2_1, strides=[1, stride, stride, 1],\n",
    "                                           padding='SAME')),\n",
    "                       tf.nn.conv2d(bn_layer3[:, :, :, :int(l2r * filter_shape[2])], filter2_2, strides=[1, stride, stride, 1], padding='SAME')), 3)\n",
    "    conv3 = tf.concat((tf.add(conv3, tf.nn.conv2d(bn_layer3[:, :, :, int(l2r * filter_shape[2]):], filter3_1, strides=[1, stride, stride, 1], padding='SAME')),\n",
    "                       tf.nn.conv2d(bn_layer3, filter3_2, strides=[1, stride, stride, 1], padding='SAME')), 3)\n",
    "\n",
    "    return conv1, conv2, conv3\n",
    "\n",
    "\n",
    "def residual_block(input1, input2, input3, output_channel, wide_scale, is_training, first_block=False):\n",
    "\n",
    "    input_channel = input3.get_shape().as_list()[-1]\n",
    "\n",
    "    # When it's time to \"shrink\" the image size, we use stride = 2\n",
    "    output_channel = int(output_channel * wide_scale)\n",
    "\n",
    "    if input_channel * wide_scale == output_channel:\n",
    "        increase_dim = True\n",
    "        stride = 1\n",
    "    else:\n",
    "        if input_channel * 2 == output_channel:\n",
    "            increase_dim = True\n",
    "            stride = 2\n",
    "        elif input_channel == output_channel:\n",
    "            increase_dim = False\n",
    "            stride = 1\n",
    "        else:\n",
    "            raise ValueError('Output and input channel does not match in residual blocks!!!')\n",
    "\n",
    "    # The first conv layer of the first residual block does not need to be normalized and relu-ed.\n",
    "    with tf.variable_scope('conv1_in_block'):\n",
    "        if first_block:\n",
    "            conv1, conv2, conv3 = conv_layer(input1, [3, 3, input_channel, output_channel], stride, is_training)\n",
    "        else:\n",
    "            conv1, conv2, conv3 = bn_relu_conv_layer(input1, input2, input3, [3, 3, input_channel, output_channel], stride, is_training)\n",
    "\n",
    "    with tf.variable_scope('conv2_in_block'):\n",
    "        conv1, conv2, conv3 = bn_relu_conv_layer(conv1, conv2, conv3, [3, 3, output_channel, output_channel], 1, is_training)\n",
    "\n",
    "    # When the channels of input layer and conv2 does not match, we add zero pads to increase the\n",
    "    #  depth of input layers\n",
    "    if increase_dim is True:\n",
    "        if input_channel * wide_scale == output_channel:\n",
    "            if first_block:\n",
    "                np0 = int((output_channel * l1r - input_channel) / 2)\n",
    "                np1 = int((output_channel * l2r - input_channel) / 2)\n",
    "                np2 = int((output_channel * 1 - input_channel) / 2)\n",
    "                padded_input1 = tf.pad(input1, [[0, 0], [0, 0], [0, 0], [np0, np0]])\n",
    "                padded_input2 = tf.pad(input2, [[0, 0], [0, 0], [0, 0], [np1, np1]])\n",
    "                padded_input3 = tf.pad(input3, [[0, 0], [0, 0], [0, 0], [np2, np2]])\n",
    "            else:\n",
    "                np1 = int((output_channel - input_channel) / 2 * l1r)\n",
    "                np2 = int((output_channel - input_channel) / 2 * l2r)\n",
    "                np3 = int((output_channel - input_channel) / 2)\n",
    "                padded_input1 = tf.pad(input1, [[0, 0], [0, 0], [0, 0], [np1, np1]])\n",
    "                padded_input2 = tf.pad(input2, [[0, 0], [0, 0], [0, 0], [np2, np2]])\n",
    "                padded_input3 = tf.pad(input3, [[0, 0], [0, 0], [0, 0], [np3, np3]])\n",
    "        else:\n",
    "            pooled_input1 = tf.nn.avg_pool(input1, ksize=[1, 2, 2, 1],\n",
    "                                          strides=[1, 2, 2, 1], padding='VALID')\n",
    "            padded_input1 = tf.pad(pooled_input1, [[0, 0], [0, 0], [0, 0], [int(input_channel*l1r) // 2,\n",
    "                                                                            int(input_channel*l1r) // 2]])\n",
    "            pooled_input2 = tf.nn.avg_pool(input2, ksize=[1, 2, 2, 1],\n",
    "                                          strides=[1, 2, 2, 1], padding='VALID')\n",
    "            padded_input2 = tf.pad(pooled_input2, [[0, 0], [0, 0], [0, 0], [int(input_channel*l2r) // 2,\n",
    "                                                                            int(input_channel*l2r) // 2]])\n",
    "            pooled_input3 = tf.nn.avg_pool(input3, ksize=[1, 2, 2, 1],\n",
    "                                          strides=[1, 2, 2, 1], padding='VALID')\n",
    "            padded_input3 = tf.pad(pooled_input3, [[0, 0], [0, 0], [0, 0], [input_channel // 2,\n",
    "                                                                            input_channel // 2]])\n",
    "    else:\n",
    "        padded_input1 = input1\n",
    "        padded_input2 = input2\n",
    "        padded_input3 = input3\n",
    "\n",
    "    output1 = conv1 + padded_input1\n",
    "    output2 = conv2 + padded_input2\n",
    "    output3 = conv3 + padded_input3\n",
    "\n",
    "    return output1, output2, output3\n",
    "\n",
    "# Code from NestedNet END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper layer functions\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_relu(input1, input2, input3, size):\n",
    "\tsize1 = int(size*l1r)\n",
    "\tsize2 = int(size*l2r) - int(size*l1r)\n",
    "\tsize3 = size - int(size*l2r)\n",
    "\n",
    "\tbias1 = bias_variable(shape=(size1,))\n",
    "\tbias2 = tf.concat((bias1, bias_variable(shape=(size2,))),0)\n",
    "\tbias3 = tf.concat((bias2, bias_variable(shape=(size3,))),0)\n",
    "\n",
    "\trelu1 = tf.nn.relu(input1 + bias1)\n",
    "\trelu2 = tf.nn.relu(input2 + bias2)\n",
    "\trelu3 = tf.nn.relu(input3 + bias3)\n",
    "\treturn relu1, relu2, relu3\n",
    "\n",
    "def inference(x, is_training):\n",
    "\twith tf.variable_scope('conv1_in_block'):\n",
    "\t\tconv1_1, conv1_2, conv1_3 = conv_layer(x, [3,3,3,16], 1, is_training)\n",
    "\n",
    "\trelu1_1, relu1_2, relu1_3 = nested_relu(conv1_1, conv1_2, conv1_3, 16)\n",
    "\t\n",
    "\twith tf.variable_scope('conv2_in_block'):\n",
    "\t\tconv2_1, conv2_2, conv2_3 = bn_relu_conv_layer(relu1_1, relu1_2, relu1_3, [3, 3, 16, 16], 1, is_training)\n",
    "\n",
    "\trelu2_1, relu2_2, relu2_3 = nested_relu(conv2_1, conv2_2, conv2_3, 16)\n",
    "\t\n",
    "\twith tf.variable_scope('conv3_in_block'):\n",
    "\t\tconv3_1, conv3_2, conv3_3 = bn_relu_conv_layer(relu2_1, relu2_2, relu2_3, [3, 3, 16, 16], 1, is_training)\n",
    "\n",
    "\trelu3_1, relu3_2, relu3_3 = nested_relu(conv3_1, conv3_2, conv3_3, 16)\n",
    "\n",
    "\twith tf.variable_scope('fc1_in_block'):\n",
    "\t\tlogits1, logits2, logits3 = output_layer(relu3_1, relu3_2, relu3_3, 3)\n",
    "\n",
    "\treturn logits1, logits2, logits3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameters\n",
    "max_epochs = 25\n",
    "# the path where our training data is stored\n",
    "base_image_path = \"img/\"\n",
    "# subdirectories in the images folder, each one representing a different class\n",
    "image_types = [\"red\", \"green\", \"yellow\"]\n",
    "# width and height of the images\n",
    "input_img_x = 32\n",
    "input_img_y = 32\n",
    "# the ratio of training images to testing images\n",
    "train_test_split_ratio = 0.9\n",
    "# the minibatch size\n",
    "batch_size = 32\n",
    "# where we will save our best model\n",
    "checkpoint_name = \"model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (Init input and output neurons)\n",
    "# input neurons are shape of image which is (32 x 32 x 3)\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_img_x, input_img_y, 3])\n",
    "# as many output neurons as classes - data is one-hot encoded\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, len(image_types)])\n",
    "# probability that a neuron's output is kept furing dropout\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x):\n",
    "    x_image = x\n",
    "\n",
    "    # First three convolutional layers, of 16 3x3 filters\n",
    "\n",
    "    # specify number of weights\n",
    "    W_conv1 = weight_variable([3, 3, 3, 16])\n",
    "    # specify number of bias variables or the variables that will\n",
    "    # be added to weights after multiplying them by the activation\n",
    "    b_conv1 = bias_variable([16]) \n",
    "    # specify the activation\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 1) + b_conv1)\n",
    "    \n",
    "    W_conv2 = weight_variable([3, 3, 16, 16])\n",
    "    b_conv2 = bias_variable([16]) \n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 1) + b_conv2)\n",
    "\n",
    "    W_conv3 = weight_variable([3, 3, 16, 16])\n",
    "    b_conv3 = bias_variable([16])\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 1) + b_conv3)\n",
    "\n",
    "    # Pooling layer\n",
    "    h_pool4 = max_pool_2x2(h_conv3)\n",
    "    n1, n2, n3, n4 = h_pool4.get_shape().as_list()\n",
    "    W_fc1 = weight_variable([n2*n3*n4, 3])\n",
    "    b_fc1 = bias_variable([3])\n",
    "\n",
    "    # Flatten pool layer into a fully connected layer\n",
    "    h_pool4_flat = tf.reshape(h_pool4, [-1, n2*n3*n4])\n",
    "    logits = tf.matmul(h_pool4_flat, W_fc1) + b_fc1\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'initializers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f0e71d090521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogits1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-b540f962bbf2>\u001b[0m in \u001b[0;36minference\u001b[0;34m(x, is_training)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fc1_in_block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mlogits1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu3_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu3_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu3_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-fc94f1a73d4f>\u001b[0m in \u001b[0;36moutput_layer\u001b[0;34m(input1, input2, input3, num_labels)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0minput_dim3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mfc_w1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fc_weights_l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_dim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mfc_w2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fc_weights_l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_dim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mfc_w3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fc_weights_l3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_dim3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'initializers'"
     ]
    }
   ],
   "source": [
    "logits = conv_net(x)\n",
    "logits1, logits2, logits3 = inference(x, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function as computing softmax, and then cross entropy\n",
    "loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits1, labels=y_))\n",
    "loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits2, labels=y_))\n",
    "loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits3, labels=y_))\n",
    "loss_function = (loss1 + loss2 + loss3)/3\n",
    "\n",
    "# Specify ptimizer takes a learning rate, and a loss function\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss=loss_function)\n",
    "\n",
    "# Initialize all variables which will show if the model is valid\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "v_loss = least_loss = 99999999\n",
    "\n",
    "# Load data\n",
    "full_set = []\n",
    "\n",
    "for im_type in image_types:\n",
    "    for ex in glob.glob(os.path.join(base_image_path, im_type, \"*\")):\n",
    "        im = cv2.imread(ex) # load img\n",
    "        if not im is None:\n",
    "            im = cv2.resize(im, (32, 32)) # resize to input size\n",
    "\n",
    "            # Create an array representing our classes and set it\n",
    "            one_hot_array = [0] * len(image_types)\n",
    "            one_hot_array[image_types.index(im_type)] = 1\n",
    "            assert(im.shape == (32, 32, 3))\n",
    "\n",
    "            full_set.append((im, one_hot_array, ex))\n",
    "\n",
    "random.shuffle(full_set) # shuffle data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into a training and test set \n",
    "\n",
    "split_index = int(math.floor(len(full_set) * train_test_split_ratio))\n",
    "train_set = full_set[:split_index]\n",
    "test_set = full_set[split_index:]\n",
    "\n",
    "# Ensure that training and test sets are a multiple of batch size\n",
    "train_set_offset = len(train_set) % batch_size\n",
    "test_set_offset = len(test_set) % batch_size\n",
    "train_set = train_set[: len(train_set) - train_set_offset]\n",
    "test_set = test_set[: len(test_set) - test_set_offset]\n",
    "\n",
    "train_x, train_y, train_z = zip(*train_set)\n",
    "test_x, test_y, test_z = zip(*test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training... [{} training examples]\".format(len(train_x)))\n",
    "\n",
    "v_loss = 9999999\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for i in range(0, max_epochs):\n",
    "\n",
    "    # Iterate over our training set\n",
    "    for tt in range(0, int(len(train_x) / batch_size)):\n",
    "        start_batch = batch_size * tt\n",
    "        end_batch = batch_size * (tt + 1)\n",
    "        train_step.run(feed_dict={x: train_x[start_batch:end_batch], y_: train_y[start_batch:end_batch]})\n",
    "        ex_seen = \"Current epoch, examples seen: {:20} / {} \\r\".format(tt * batch_size, len(train_x))\n",
    "        sys.stdout.write(ex_seen.format(tt * batch_size))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    ex_seen = \"Current epoch, examples seen: {:20} / {} \\r\".format((tt + 1) * batch_size, len(train_x))\n",
    "    sys.stdout.write(ex_seen.format(tt * batch_size))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    t_loss = loss_function.eval(feed_dict={x: train_x, y_: train_y})\n",
    "    v_loss = loss_function.eval(feed_dict={x: test_x, y_: test_y})\n",
    "    \n",
    "    train_loss.append(t_loss)\n",
    "    val_loss.append(v_loss)\n",
    "    \n",
    "    sys.stdout.write(\"Epoch {:5}: loss: {:15.10f}, val. loss: {:15.10f}\".format(i + 1, t_loss, v_loss))\n",
    "    \n",
    "    if v_loss < least_loss:\n",
    "        sys.stdout.write(\", saving new best model to {}\".format(checkpoint_name))\n",
    "        least_loss = v_loss\n",
    "        filename = saver.save(sess, checkpoint_name)\n",
    "        \n",
    "    sys.stdout.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
